---
slug: 6-13-news
title: 6月13日更新
authors:
  name: Kyrie
  title: Author
  url: https://github.com/KyrieCui
  image_url: https://avatars.githubusercontent.com/u/37808472?v=4
tags: [AI, LLM]
---
## Stablity AI老板陷丑闻漩涡

详情可见量子位：AIGC明星独角兽爆雷！7亿融资烧大半，拖欠员工工资，创始人被扒得千疮百孔
文章的主要要点：
学历和工作经历造假：伊玛德被指控伪造了他的牛津大学硕士学位，他也被指控在他的工作经历中夸大了他的成就。
窃取他人成果：Stability AI被指控窃取了Stable Diffusion的代码成果，这是由慕尼黑大学、海德堡大学和AI初创公司Runway共同完成的项目。
拖欠员工工资和税款：公司被指控拖欠大量员工工资和税款，甚至英国税务机构都威胁要没收公司资产。
夸大公司收入和融资困难：伊玛德被指控夸大了Stability AI公司的收入，他声称公司年收入已超过1000万美元，但知情人士表示，公司销售额并没有改善。此外，尽管Stability AI收入并不可观，伊玛德最初还是通过各种办法搞到了约1亿美元的融资，但现在，他遭到了很多投资人的质疑。
夸大与亚马逊的合作：伊玛德告诉投资人Stability AI正在组装世界上最大的10台超算之一，然后亚马逊以80%的折扣卖给他计算资源服务，因为Stability AI“跟亚马逊具有战略合作伙伴关系”。然而实际上，只要是任何跟亚马逊有长期租赁合作的客户都能享受这一标准折扣。
版权官司：伊玛德还被指控Stability AI违反版权法训练模型，遭到了盖蒂图片社和艺术家的集体诉讼。
公司运营问题：Stability AI自身也面临严重问题，被曝出疯狂烧钱、管理混乱等问题。尽管去年10月拿到了1亿美元融资，但Stability AI走得一直不算顺利。
伊玛德对这些指控进行了回应，但部分人并不买帐，因为关于文章中一些很关键的点，伊玛德并没有澄清。

## 北京智源大会2023：“AI春晚”

大会主要看点：
四位图灵奖得主、OpenAI创始人、以及张钹、张宏江等国内外AI最前沿领军人物
发布了一系列重磅的人工智能大模型，其中包括“悟道3.0”，并且全面开源。
“悟道3.0”包括了一系列的大模型，如“悟道·天鹰（Aquila）”语言大模型系列，这是首个支持中英双语知识、商用许可的模型。
发布了“天秤（FlagEval）”大语言评测体系及开放平台，构建了“能力-任务-指标”三维评测框架，细粒度刻画模型的认知能力边界。
开源了“悟道·视界”视觉大模型系列，包含了国际领先的6项成果，如性能最强的开源CLIP模型EVA-CLIP，以及新鲜出炉的多模态输入并多模态输出的Emu多模态大模型等。
智源研究院构建了支持多种深度学习框架、多种AI芯片系统的大模型开源技术体系，可以说“悟道3.0”是迈向了全面开源的新阶段。

## Midjourney Office Hour最新消息

主要内容如下：
Alpha web正在进行重构，因此暂时搁置。
V6版本仍然落后，团队正在进行重构。
正在准备v6训练的数据，预计至少还需要一个月的时间才能进行v6的重新训练。
5.2版本的发布将专注于可控性和工作流程，目前正在积极测试一些外部绘制的东西，希望能在5.2更新中加入。
正在开发新的美学，更多的决定性，5.2版本将在本月发布，6.0版本将在下个月发布。
正在进行高级研发，包括从实时绘图到3D的所有内容。
正在开发高分辨率的生成工具，以及一个可以告诉你哪些提示在你的提示中起作用的工具。
正在开发更多的教育内容，"超级专业"层级将在接下来的几周内推出。
原推文链接：https://nitter.net/nickfloats/status/1666527869907120129#m

## Runway宣布GEN-2已可在网页和移动端使用
目前一次只能生成4秒钟，但非常流畅，连续性也很好，相比一代提升很大。
网页地址：https://runwayml.com/

## OpenAI发布测试工具：我们不会偷偷更换模型

OpenAI发布了模型质量的测试工具，如果怀疑模型质量下降或者模型被更换可以测一下，还强调了他们不会不经过说明偷偷更换模型

## 科大讯飞：将发布讯飞星火认知大模型 V1.5

6 月 6 日消息，科大讯飞现发布公告，宣布该公司将在 6 月 9 日如期发布讯飞星火认知大模型的新进展，而且本次发布会将发布讯飞星火认知大模型 V1.5。
据介绍，讯飞星火认知大模型」V1.5 开放式问答取得突破，多轮对话和数学能力再升级，文本生成、语言理解、逻辑推理能力持续提升。此外，星火认知大模型在学习、医疗、工业、办公等领域进一步的商业落地成果亦将同步发布。

## ChatGPT App更新：可支持Siri

更新的主要内容：
适配 iPad（但不支持在 Mac 上安装）
支持拖动单条消息到其他 App
支持 Siri 和捷径

## Google宣布开放其生成AI：Vertex AI


开发者可以访问由PaLM 2驱动的文本模型，以及Model Garden中的其他基础模型，还可以利用生成性AI Studio中的用户友好工具进行模型调整和部署。
项目地址：https://cloud.google.com/vertex-ai

## Meta刚刚发布MusicGen

MusicGen是一个单阶自回归Transformer模型，它是通过一个在32kHz EnCodec tokenizer上进行训练，具有4个以50Hz采样的码本。
演示地址：http://t.cn/A6pJHGTd
项目首页：github.com/facebookresearch/

## MiSiMO本周周刊

（「週刊MiSiMO」是由MiSiMO（みしも）编写的关注AI图像生成和相关技术的周刊，内容非常丰富，推荐订阅。）
本周周刊主要内容：
技术内容：本期的内容主要集中在各种技术主题上，包括Adobe FireFly的生成性填充技术、Photopea的扩展、手和身体的修正技术、After Detailer的使用、以及ControlNet的使用等。
动画：介绍了Runway Gen2的发布，以及如何利用VRoid生成动画。
解决方案：分享了一些解决AI生成图像中常见问题的方法，如解决解析度问题、指破裂问题等。
工作流程介绍：介绍了一些创新的工作流程，如如何将动漫和现实共存，以及如何使用LoRA等。
新工具和更新：介绍了一些新的工具和更新，如AUTOMATIC1111 v1.3.0的更新，BracingEvoMix的发布等。
周报链接：https://note.com/misimo_ai/n/nd8a5c41ae57c

## 一个响指进入虚拟世界！
Reddit又来神作啦！短短一天，已在r/ChatGPT收获7.5k赞。
不过目前作者没有公布技术细节，只在标题透露使用了GEN-2 技术将文本转换为视频。
Reddit链接：https://www.reddit.com/r/ChatGPT/comments/145w7j9/txttovideo_with_gen2_ai/

##  Make-Your-Video：从想象到视频

"Make-Your-Video"是一个由国内研究者开发的视频生成模型，它允许用户通过文本和运动结构（例如逐帧深度）进行定制化的视频生成。
该模型首先使用预训练的Latent Diffusion Model进行静态图像合成，然后引入时间模块进行视频生成。此外，该模型使用了一种简单而有效的因果注意力掩码策略，使得可以进行更长的视频合成，同时有效地减少了潜在的质量下降。
Github链接：https://github.com/VideoCrafter/Make-Your-Video

##  AI生成的艺术二维码：真的能扫出来！

Reddit又双来神作啦！一个星期，已收获7k+赞。
作者分享了一个 QR 码生成模型的链接，但该链接已被删除。
感觉是个很好的idea，希望有人能复现。
Reddit链接：https://www.reddit.com/r/StableDiffusion/comments/141hg9x/controlnet_for_qr_code/
量子位链接：ControlNet新玩法爆火：画出可扫码插画，内容链接任意指定
丐版平替：https://qrbtf.com/

## 一个ChatGPT插件组合玩法
（由Twitter@向阳乔木 大佬推荐）
用到的工具如下：
AI agents：类似AutoGPT和BabyAGI的任务拆解调度工具。
WebPilot：实时网页访问抓取工具。（或用其他网页读取插件，如Web requests）
Noteable：类似Jupyter和谷歌Colab的笔记本，支持Markdown和在线协作分享。
AI agents利用GPT4推理能力拆解目标为子任务，子任务调WebPilot抓取网页信息，Noteable用于存储处理结果。
配置并选中这三个插件，像写OKR一样，告诉AI你的目标（Objective）任务，ChatGPT会自动运行AI agents插件，接着会调用WebPilot读网页（不停地读），然后写入Noteable。另外可以回复“Keep going”或“Continue”让GPT持续运行。
（感觉会很适合写报告/总结/综述一类的文章）
推特链接：https://nitter.net/vista8/status/1667566878624202753#m
ChatGPT对话记录：https://chat.openai.com/share/72f09df0-30a2-4464-803a-928b2d0f65d0

## Pluginpedia：帮你搜寻ChatGPT插件的插件

是不是不知道ChatGPT两百多个插件如何选择？现在好了，只需一个插件，安装后只需告诉它你需要什么样的插件，它会帮你推荐和介绍 😄

## Roop：一段视频+一张照片，一键换脸

可以使用一张照片制作深度伪造视频，而不需要训练。
该项目已在Github获得10.1k+⭐️。
项目地址：https://github.com/s0md3v/roop

## Flair：轻松生成产品宣传图

Flair是一个AI设计工具，专为品牌内容创建而设计。
用户可以通过几次点击开始使用：首先将产品照片拖入Canvas，然后可视化描述产品周围的场景，最后编辑、导出和分享。通过使用配件，用户可以在产品周围构建一个世界，Flair AI将填充空白空间。
用户反馈显示，Flair对于需要创建新内容的用户（比如淘宝店铺）来说是一个游戏规则改变者，它既高质量又易于使用，快速且价格合理。
项目地址：https://flair.ai/

## Midjourney Archive Downloader：一键下载Midjourney归档图片
Midjourney Archive Downloader是一个Chrome扩展，能够帮助你批量下载Midjourney图片；亮点如下：
允许用户选择要下载图像的日期范围，并批量下载
仅下载放大的图像
有选项下载所有v5+和niji 5+网格图像

##  SD模型漫画风LoRA公开

项目地址：https://civitai.com/models/85564?modelVersionId=90980




## AIWatch.ai：AI工具流量排行榜
这是一个实时更新的Google表格，上面按照流量排序列出了时下最热门的AI工具，大家可以看看。
网站链接：AIWatch.ai

##  AI沃茨更新啦：一键部署90%情况媲美ChatGPT的开源模型vicuna羊驼🦙

主要亮点：
colab超低成本一键部署
无需担心本地硬件
不需要耗费时间申请llamda权重
SWIFT和SAGE模块通过一个启发式算法集成在一起，该算法确定何时激活或停用SAGE模块，以及如何使用动作缓冲机制结合两个模块的输出。与以前只生成下一个立即动作的方法不同，SwiftSage参与了更长期的动作规划。

公众号链接：一口气开源大模型全学会EP1-90%情况下媲美ChatGPT的Vicuna家族（上）

## Video-LLaMA：阿里的音视频开源多模态大模型

Video-LLaMA由阿里巴巴集团的DAMO Academy的研究团队开发，它解决了整合音频-视觉信息的困难，并应对了视觉场景中时间变化的挑战，该框架赋予大型语言模型（LLMs）理解视频中的视觉和听觉内容的能力。
Video-LLaMA基于BLIP-2和MiniGPT-4构建，包含两个核心组件：视觉-语言（VL）分支和音频-语言（AL）分支。VL分支在Webvid-2M视频字幕数据集上进行训练，以执行视频到文本生成任务。AL分支则在视频/图像指令数据上进行训练，以将ImageBind的输出连接到语言解码器。
Video-LLaMA已经在大规模的视频和图像字幕对上进行了训练，可直接在Github下载。
项目链接：https://github.com/damo-nlp-sg/video-llama

## Aquila：国产从零训练可商用LLM

Aquila是一个由北京智源研究院（即，BAAI，曾开发过悟道2.0/3.0）开发的大型语言模型，它继承了GPT-3和LLaMA的架构设计优点，并替换了一批更高效的底层算子实现。
Aquila是在中英文高质量语料基础上从零开始训练的，通过数据质量的控制和多种训练优化方法，实现了在更小的数据集和更短的训练时间内，获得比其他开源模型更优的性能，尤其中文能力很强。Aquila模型还是首个支持中英双语知识、支持商用许可协议、符合国内数据合规需要的大规模开源语言模型。
Github链接：https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila

## 多模态大模型论文合集：按图索骥找所有MLLM
该论文集实时更新，已收获近900⭐️；目前包含的论文种类有：
多模态指令调优
多模态上下文学习
多模态思维链
LLM辅助视觉推理
基础模型
包含的数据集有：
用来对齐的预训练数据集
多模态指令调优数据集
上下文学习数据集
多模态思维链数据集
Github链接：https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models

## Amazon Lex × Langchain × SageMaker：利用Amazon服务部署你的客服机器人

这篇文章介绍了如何使用Amazon Lex、Langchain和SageMaker Jumpstart来探索生成性AI在对话体验中的应用。
文章强调了大语言模型（LLMs）在生成性AI聊天机器人中的作用，这些机器人能够模仿人类的智能，并使用LLMs进行文本分析和内容生成。
文章提供了一个示例项目，该项目可以快速部署一个使用预训练的开源LLM的Amazon Lex机器人。该代码还包括实现自定义内存管理器的起点，该机制允许LLM回忆以前的互动，以保持对话的上下文和节奏。文章还强调了实验性地调整提示和LLM的随机性和决定性参数以获得一致结果的重要性。
文章链接：https://aws.amazon.com/blogs/machine-learning/exploring-generative-ai-in-conversational-experiences-an-introduction-with-amazon-lex-langchain-and-sagemaker-jumpstart/

## OpenChat：一步部署本地聊天机器人
OpenChat是一个开源项目，旨在简化大型语言模型的使用，为用户提供一个一站式的聊天机器人控制台。
只需上传相关数据，你就可以得到一个可嵌入网站的聊天机器人。该项目正在积极努力整合各种开源驱动程序，并与 Notion、Confluence 和 Office 365 等平台集成。

但有评论者对于依赖 OpenAI 服务器以及需要更好的嵌入方法和数据隐私表示担忧。
项目地址：https://github.com/openchatai/OpenChat
## SAIL-7B：比ChatGPT更小但更强？

SAIL-7B是一个由MIT CSAIL、MIT Linguistics和CUHK & CPII等机构的研究者开发的搜索引擎增强的大型语言模型。
该模型的独特之处在于，它能够自动提炼出有用的搜索结果并标记出干扰项。该模型使用 GPT-4 进行指令跟随自动评分，以更少的参数超越了包括ChatGPT和Vicuna-13B在内的最先进的聊天机器人。
项目地址：https://openlsr.org/sail-7b
## OpenAI官方出的Prompt教程

主要内容有：
写清楚的说明：具体包括查询中包含更详细的信息、让模型代入角色、使用分隔符指示输入的不同部分、指定完成任务所需步骤、提供示例、指定所需输出长度等。
提供参考文本：就像一张笔记可以帮助学生在考试中做得更好一样，向 GPT 提供参考文本可以帮助以更少的捏造来回答。
将复杂任务拆分成更简单的子任务：具体包括使用意图分类来确定最相关的查询、对于很长的对话汇总之前的对话历史、分段汇总长文档，递归构建完整摘要
给GPT时间思考：具体包括指示模型先指定自己的解决方案再得出结论、使用一系列提示来隐藏模型的推理过程、询问模型是否遗漏了以前的某些内容
使用外部工具：具体包括使用基于嵌入的搜索、以及使用代码实现更准确的计算
系统的测试更改：如果可以衡量性能，则提高性能会更容易。
官方文档链接：https://platform.openai.com/docs/guides/gpt-best-practices/six-strategies-for-getting-better-results

##  Langchain × Vectara：高度精确检索
LangChain和Vectara联合推出了一种新的解决方案，以简化大型语言模型（LLM）应用的开发。
Vectara是一个GenAI会话搜索平台，它提供了一个基于神经搜索核心的API，可以实现查询和相关文档之间的高度精确匹配。此外，LangChain和Vectara的结合还提供了“基于检索的生成”功能，这是一种解决LLM数据最新性和幻觉问题的通用方法。
例如，如果你向ChatGPT询问关于硅谷银行的问题，它会根据其在2022年之前接受的训练数据提供回答，而对银行最近的崩溃一无所知。通过使用Vectara，开发者可以利用其“基于检索的生成”功能，从而提供基于所有相关已知事实的准确回应。
项目地址：https://console.vectara.com/signup
博客链接：https://blog.langchain.dev/langchain-vectara-better-together/

## GPTeam：用GPT打造一支AI团队

GPTeam的灵感来源于斯坦福大学的那篇著名的"生成代理"论文，每个代理在GPTeam模拟中都有自己独特的个性、记忆和指令，这导致了他们在互动时产生有趣的新行为。
GPTeam的架构包括"世界"类作为所有其他内容的顶级包装器。当运行模拟时，我们运行world.run()，这会触发世界中的每个代理开始其代理循环。
每个代理循环包括观察、规划、反应、行动和反思五个步骤。代理循环是GPTeam活动的主要驱动器。当世界运行时，每个代理反复执行这个循环，直到世界停止。
这个项目的亮点在于，它不仅可以用于测试LLMs模拟人类社交行为的能力，还可以用于交互式娱乐，比如创建自己的多代理模拟，或者在视频游戏中创建有机的、永不结束的NPC互动。

项目地址：https://github.com/101dotxyz/GPTeam

## RedPajama 7B发布：在HELM基准上超过其他所有7B模型
在 HELM 基准测试中表现优异，超越所有其他 7B 模型。该项目旨在创建一组领先的开源模型，并了解产生良好性能的因素。
RedPajama-INCITE 系列模型（包括指令调整和聊天版本）现已提供 Apache 2.0 许可证。聊天模型建立在完全开放数据上，不使用 OpenAI 等封闭模型的蒸馏数据。
项目地址：https://www.together.xyz/blog/redpajama-7b

